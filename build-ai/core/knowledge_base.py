# core/knowledge_base.py
import json
import hashlib
from typing import List, Dict, Optional
import chromadb
from sentence_transformers import SentenceTransformer
from chromadb.config import Settings
from pathlib import Path

class KnowledgeBase:
    """å‘é‡çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.kb_path = Path(config["path"])
        self.embedder = None
        self.client = None
        self.collection = None
        
        self._init_knowledge_base()
    
    def _init_knowledge_base(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        # 1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        print("ğŸ”§ åŠ è½½åµŒå…¥æ¨¡å‹...")
        self.embedder = SentenceTransformer(self.config["embedder_model"])
        
        # 2. åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
        print("ğŸ“š åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        self.client = chromadb.PersistentClient(
            path=str(self.kb_path),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # 3. è·å–æˆ–åˆ›å»ºé›†åˆ
        try:
            self.collection = self.client.get_collection(
                name=self.config["collection_name"]
            )
            print(f"âœ… åŠ è½½å·²æœ‰çŸ¥è¯†åº“ï¼Œæ–‡æ¡£æ•°: {self.collection.count()}")
        except:
            self.collection = self.client.create_collection(
                name=self.config["collection_name"],
                metadata={"description": "åä¸ºäº‘æ„å»ºé”™è¯¯è§£å†³æ–¹æ¡ˆçŸ¥è¯†åº“"}
            )
            print("âœ… åˆ›å»ºæ–°çš„çŸ¥è¯†åº“")
        
        # 4. åŠ è½½åˆå§‹çŸ¥è¯†
        self._load_initial_knowledge()
    
    def _load_initial_knowledge(self):
        """åŠ è½½åˆå§‹çŸ¥è¯†æ–‡æ¡£"""
        initial_knowledge = [
            {
                "content": """åä¸ºäº‘ç¼–è¯‘æ„å»ºå¸¸è§é”™è¯¯ï¼šä¾èµ–ä¸‹è½½å¤±è´¥
è§£å†³æ–¹æ¡ˆï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼šping repo.huaweicloud.com
2. é…ç½®é•œåƒæºï¼šnpm config set registry https://repo.huaweicloud.com/repository/npm/
3. æ¸…ç†ç¼“å­˜ï¼šnpm cache clean --force
4. é‡è¯•æ„å»º""",
                "metadata": {
                    "source": "manual",
                    "error_type": "dependency",
                    "keywords": "npmä¾èµ– ä¸‹è½½å¤±è´¥"
                }
            },
            {
                "content": """Dockeræ„å»ºé”™è¯¯ï¼šæƒé™ä¸è¶³
è§£å†³æ–¹æ¡ˆï¼š
1. æ£€æŸ¥DockeræœåŠ¡çŠ¶æ€ï¼šsystemctl status docker
2. æ·»åŠ ç”¨æˆ·åˆ°dockerç»„ï¼šsudo usermod -aG docker $USER
3. é‡æ–°ç™»å½•ç”Ÿæ•ˆ
4. æ£€æŸ¥é•œåƒä»“åº“æƒé™""",
                "metadata": {
                    "source": "manual", 
                    "error_type": "permission",
                    "keywords": "docker, æƒé™, permission denied"
                }
            },
            {
                "content": """Mavenæ„å»ºé”™è¯¯ï¼šå†…å­˜ä¸è¶³
è§£å†³æ–¹æ¡ˆï¼š
1. è°ƒæ•´Mavenå†…å­˜è®¾ç½®ï¼šexport MAVEN_OPTS="-Xmx2048m -Xms1024m"
2. è·³è¿‡æµ‹è¯•ï¼šmvn clean install -DskipTests
3. ä½¿ç”¨å¢é‡ç¼–è¯‘
4. æ£€æŸ¥JVMé…ç½®""",
                "metadata": {
                    "source": "manual",
                    "error_type": "resource",
                    "keywords": "maven å†…å­˜ out of memory"
                }
            }
        ]
        
        # å¦‚æœçŸ¥è¯†åº“ä¸ºç©ºï¼Œæ·»åŠ åˆå§‹çŸ¥è¯†
        if self.collection.count() == 0:
            print("ğŸ“– æ·»åŠ åˆå§‹çŸ¥è¯†æ–‡æ¡£...")
            for i, doc in enumerate(initial_knowledge):
                self.add_document(
                    content=doc["content"],
                    metadata=doc["metadata"]
                )
    
    def add_document(self, content: str, metadata: Dict) -> str:
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        # ç”Ÿæˆæ–‡æ¡£ID 
        doc_hash = hashlib.md5(content.encode()).hexdigest()[:16]
        doc_id = f"doc_{doc_hash}"
        
        # ç”ŸæˆåµŒå…¥å‘é‡
        embedding = self.embedder.encode(content).tolist()
        
        # æ·»åŠ å…ƒæ•°æ®
        full_metadata = metadata.copy()
        full_metadata["content_hash"] = doc_hash
        
        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        self.collection.add(
            documents=[content],
            embeddings=[embedding],
            metadatas=[full_metadata],
            ids=[doc_id]
        )
        
        print(f"âœ… æ–‡æ¡£å·²æ·»åŠ : {doc_id}")
        return doc_id
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """æœç´¢ç›¸å…³çŸ¥è¯†"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedder.encode(query).tolist()
        
        # æ‰§è¡Œæœç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        if results["documents"]:
            for i in range(len(results["documents"][0])):
                formatted_results.append({
                    "content": results["documents"][0][i],
                    "metadata": results["metadatas"][0][i],
                    "similarity": 1 - results["distances"][0][i],  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                    "rank": i + 1
                })
        
        return formatted_results
    
    def count_documents(self) -> int:
        """è·å–æ–‡æ¡£æ•°é‡"""
        return self.collection.count()